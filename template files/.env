#User settings

#Method for choosing which loose files to add to the collate file
#Either "all" or "memory"
#"all" means doing a fresh collate using ALL loose files. The history and collate files are reset before the collation as a result
#"memory" means the script checks the history file to see which loose files have already been processed and processes all files not listed in the history csv
METHOD = "memory"

#Flag for the data to be uploaded to SQL
#"always", "never", "on change"
#For "on change" it will always upload if Method is "all"
SQL_UPLOAD = "on change"
#Bool to say if the target table should be replaced (True) or appened (False)
SQL_REPLACE = TRUE

### MODIFY ###
#SQL Database
SQL_DATABASE = ""
### MODIFY ###
#SQL Schema (default "dbo")
SQL_SCHEMA = "dbo"
### MODIFY ###
#SQL Table name
SQL_TABLE = ""

###Program settings#################
###Should be largely untouched
#Directory path to the loose files
PATH_PREFIX = "./source/"
#Default map to use if unspecified
DEFAULT_MAP = "base"

### MODIFY ###
#Label the output data with a column holding the filename the data came from
#Either this is set to an empty string "" (disables feature) or to the name of the output column that should hold the label
#Note the program will not use the label in the output if the column is not also specified in the output_columns array,
#Note the program will OVERWRITE source data in the output if the column is also specified in the mapping_columns dict
LABEL_DATA = ""

#Affects performance, for data for more output columns, decrease this value
#MSSQL has a hard limit of 2100 parameters (Number of columns * Chunksize)
#Lower if you get an error about exceeding the maximum parameter limit
SQL_CHUNKSIZE = 100

#If True then will use specified output_dtypes object to determine sql column types (Should be used for date columns)
SQL_DTYPES = True

### MODIFY ###
#Connection string parametes
#Should be fixed but store here to avoid being visable on github
SQL_ADDRESS = ""